{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jumlah Kasus</th>\n",
       "      <th>Curah hujan</th>\n",
       "      <th>Kelembapan</th>\n",
       "      <th>Temperatur</th>\n",
       "      <th>Label Kelas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>137</td>\n",
       "      <td>149.06</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136</td>\n",
       "      <td>149.06</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207</td>\n",
       "      <td>149.06</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>267</td>\n",
       "      <td>322.04</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>232</td>\n",
       "      <td>149.06</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Jumlah Kasus  Curah hujan  Kelembapan  Temperatur  Label Kelas\n",
       "0           137       149.06        23.4        0.76            2\n",
       "1           136       149.06        23.4        0.76            2\n",
       "2           207       149.06        23.4        0.76            2\n",
       "3           267       322.04        23.3        0.84            2\n",
       "4           232       149.06        23.4        0.76            2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('dataset.xlsx')\n",
    "dbd = pd.DataFrame(data, columns= ['Jumlah Kasus','Curah hujan','Kelembapan','Temperatur','Label Kelas'])\n",
    "dbd.head()\n",
    "# dbd.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2012 = dbd.iloc[0:30]\n",
    "d2013 = dbd.iloc[30:60] \n",
    "d2014 = dbd.iloc[60:90] \n",
    "d2015 = dbd.iloc[90:120] \n",
    "d2016 = dbd.iloc[120:150] \n",
    "d2017 = dbd.iloc[150:180] \n",
    "d2018 = dbd.iloc[180:210] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Tahun Sebelumnya "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x13 = d2012.drop([\"Label Kelas\"], axis = 1)\n",
    "#Variabel dependen\n",
    "y13 = d2012[\"Label Kelas\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x13,y13, test_size = 0.2, random_state = 123)\n",
    "model13 = GaussianNB()\n",
    "nbtrain13 = model13.fit(x_train, y_train)\n",
    "y_pred = nbtrain13.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           2       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.42      0.50      0.45         6\n",
      "weighted avg       0.69      0.83      0.76         6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryuno\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x14 = d2013.drop([\"Label Kelas\"], axis = 1)\n",
    "#Variabel dependen\n",
    "y14 = d2013[\"Label Kelas\"]\n",
    "x_train14, x_test14, y_train14, y_test14 = train_test_split(x14,y14, test_size = 0.2, random_state = 123)\n",
    "model14 = GaussianNB()\n",
    "nbtrain14 = model14.fit(x_train14, y_train14)\n",
    "y_pred14 = nbtrain14.predict(x_test14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      1.00      0.40         1\n",
      "           2       1.00      0.40      0.57         5\n",
      "\n",
      "    accuracy                           0.50         6\n",
      "   macro avg       0.62      0.70      0.49         6\n",
      "weighted avg       0.88      0.50      0.54         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test14, y_pred14))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x15 = d2014.drop([\"Label Kelas\"], axis = 1)\n",
    "#Variabel dependen\n",
    "y15 = d2014[\"Label Kelas\"]\n",
    "x_train15, x_test15, y_train15, y_test15 = train_test_split(x15,y15, test_size = 0.2, random_state = 123)\n",
    "model15 = GaussianNB()\n",
    "nbtrain15 = model15.fit(x_train15, y_train15)\n",
    "y_pred15 = nbtrain15.predict(x_test15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test15, y_pred15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x16 = d2015.drop([\"Label Kelas\"], axis = 1)\n",
    "#Variabel dependen\n",
    "y16 = d2015[\"Label Kelas\"]\n",
    "x_train16, x_test16, y_train16, y_test16 = train_test_split(x16,y16, test_size = 0.2, random_state = 123)\n",
    "model16 = GaussianNB()\n",
    "nbtrain16 = model16.fit(x_train16, y_train16)\n",
    "y_pred16 = nbtrain16.predict(x_test16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.50      0.67         2\n",
      "           2       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.90      0.75      0.78         6\n",
      "weighted avg       0.87      0.83      0.81         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test16, y_pred16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x17 = d2016.drop([\"Label Kelas\"], axis = 1)\n",
    "#Variabel dependen\n",
    "y17 = d2016[\"Label Kelas\"]\n",
    "x_train17, x_test17, y_train17, y_test17 = train_test_split(x17,y17, test_size = 0.2, random_state = 123)\n",
    "model17 = GaussianNB()\n",
    "nbtrain17 = model17.fit(x_train17, y_train17)\n",
    "y_pred17 = nbtrain17.predict(x_test17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test17, y_pred17))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018 dengan atribut tahun 2017#Terbaik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x18 = d2017.drop([\"Label Kelas\"], axis = 1)\n",
    "#Variabel dependen\n",
    "y18 = d2017[\"Label Kelas\"]\n",
    "x_train18, x_test18, y_train18, y_test18 = train_test_split(x18,y18, test_size = 0.2, random_state = 123)\n",
    "model18 = GaussianNB()\n",
    "nbtrain18 = model18.fit(x_train18, y_train18)\n",
    "y_pred18 = nbtrain18.predict(x_test18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test18, y_pred18))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Tahun Sebelumnya "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a14 = d2012.drop([\"Label Kelas\"], axis = 1)\n",
    "#Variabel dependen\n",
    "b14 = d2012[\"Label Kelas\"]\n",
    "a_train14, a_test14, b_train14, b_test14 = train_test_split(a14,b14, test_size = 0.2, random_state = 123)\n",
    "modelb14 = GaussianNB()\n",
    "natrain14 = modelb14.fit(a_train14, b_train14)\n",
    "b_pred14 = natrain14.predict(a_test14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           2       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.42      0.50      0.45         6\n",
      "weighted avg       0.69      0.83      0.76         6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryuno\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(b_test14, b_pred14))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a16 = d2014.drop([\"Label Kelas\"], axis = 1)\n",
    "#Variabel dependen\n",
    "b16 = d2014[\"Label Kelas\"]\n",
    "a_train16, a_test16, b_train16, b_test16 = train_test_split(a16,b16, test_size = 0.2, random_state = 123)\n",
    "modelb16 = GaussianNB()\n",
    "natrain16 = modelb16.fit(a_train16, b_train16)\n",
    "b_pred16 = natrain16.predict(a_test16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(b_test16, b_pred16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a18 = d2016.drop([\"Label Kelas\"], axis = 1)\n",
    "#Variabel dependen\n",
    "b18 = d2016[\"Label Kelas\"]\n",
    "a_train18, a_test18, b_train18, b_test18 = train_test_split(a18,b18, test_size = 0.2, random_state = 123)\n",
    "modelb18 = GaussianNB()\n",
    "natrain18 = modelb18.fit(a_train16, b_train18)\n",
    "b_pred18 = natrain18.predict(a_test18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(b_test18, b_pred18))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Tahun Sebelumnya "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
